"""
é‡æ„åçš„æ™ºèƒ½ä½“èŠ‚ç‚¹å®ç°

è®¾è®¡åŸåˆ™ï¼š
1. æ¯ä¸ªæ™ºèƒ½ä½“æ˜¯ç‹¬ç«‹çš„èŠ‚ç‚¹å‡½æ•°
2. ä½¿ç”¨LangChainè°ƒç”¨LLMå¹¶äº§ç”Ÿç»“æ„åŒ–è¾“å‡º
3. åŸºäºæç¤ºè¯æ¨¡æ¿ç”Ÿæˆå“åº”
4. è¿”å›æ›´æ–°åçš„å…¨å±€çŠ¶æ€
5. Coordinatorä½œä¸ºçœŸæ­£çš„æ™ºèƒ½ä½“ï¼Œç”±LLMå†³ç­–ä¸‹ä¸€æ­¥
"""

from typing import Optional
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.language_models import BaseChatModel
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

from src.state.state_refactored import (
    AgentState,
    ComprehensionOutput,
    PlanningOutput,
    ExecutionOutput,
    VerificationOutput,
    ToolType,
    ToolExecutionRecord,
    VerificationStatus,
    IssueType,
    Issue,
    ProblemLevel,
    add_iteration_record
)
from src.prompts.prompt import (
    COMPREHENSION_PROMPT,
    PREPROCESSING_PROMPT,
    EXECUTION_PROMPT,
    VERIFICATION_PROMPT,
    COORDINATOR_PROMPT
)
from src.configuration import Configuration
from src.tools.sympy import create_sympy_tool
from src.tools.wolfram_alpha import create_wolfram_alpha_tool
from dotenv import load_dotenv

import os

load_dotenv()

###################
# è¾…åŠ©å‡½æ•°
###################

def get_llm(config: Optional[Configuration] = None) -> BaseChatModel:
    """è·å–é…ç½®çš„LLMå®ä¾‹"""
    if config is None:
        config = Configuration.from_runnable_config()
    
    # è¿™é‡Œå¯ä»¥æ ¹æ®é…ç½®é€‰æ‹©ä¸åŒçš„æ¨¡å‹
    # ç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨OpenAI
    return ChatOpenAI(
        model=config.coordinator_model,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1",
        temperature=0.2
    )


###################
# Coordinatorå†³ç­–æ¨¡å‹
###################

class CoordinatorDecision(BaseModel):
    """
    Coordinatorçš„å†³ç­–è¾“å‡ºï¼ˆç”±LLMç”Ÿæˆï¼‰
    
    è®©LLMæ™ºèƒ½å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç è§„åˆ™
    """
    next_action: str = Field(
        description="ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼šcomprehension/planning/execution/verification/complete"
    )
    reasoning: str = Field(
        description="å†³ç­–ç†ç”±ï¼šä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªè¡ŒåŠ¨"
    )
    instructions: str = Field(
        description="ç»™ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“çš„å…·ä½“æŒ‡ä»¤"
    )
    should_continue: bool = Field(
        description="æ˜¯å¦åº”è¯¥ç»§ç»­è¿­ä»£"
    )


class ToolSelectionDecision(BaseModel):
    """
    å·¥å…·é€‰æ‹©å†³ç­–ï¼ˆç”±LLMç”Ÿæˆï¼‰
    
    è®©LLMæ™ºèƒ½å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç å…³é”®è¯åŒ¹é…
    """
    tool_name: str = Field(
        description="é€‰æ‹©çš„å·¥å…·ï¼šsympy/wolfram_alpha/internal_reasoning"
    )
    reasoning: str = Field(
        description="é€‰æ‹©ç†ç”±ï¼šä¸ºä»€ä¹ˆè¿™ä¸ªå·¥å…·æœ€é€‚åˆè¿™ä¸ªä»»åŠ¡"
    )
    confidence: float = Field(
        description="é€‰æ‹©çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰"
    )


###################
# åè°ƒç®¡ç†æ™ºèƒ½ä½“ï¼ˆCoordinator Agentï¼‰- agent.mdçš„çµé­‚
###################

def coordinator_agent(state: AgentState, config: Optional[Configuration] = None) -> AgentState:
    """
    åè°ƒç®¡ç†æ™ºèƒ½ä½“ï¼ˆagent.md: æµç¨‹æ§åˆ¶å™¨ã€å®ˆé—¨å‘˜ï¼‰
    
    èŒè´£ï¼š
    1. åˆ†æå½“å‰çŠ¶æ€å’ŒéªŒè¯åé¦ˆ
    2. æ™ºèƒ½å†³ç­–ä¸‹ä¸€æ­¥åº”è¯¥è°ƒç”¨å“ªä¸ªagent
    3. å†³å®šæ˜¯ç»§ç»­è¿­ä»£è¿˜æ˜¯ç»“æŸæµç¨‹
    4. ç”±LLMåšå†³ç­–ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç è§„åˆ™
    
    è¿™æ˜¯agent.mdä¸­æè¿°çš„çœŸæ­£çš„"åè°ƒç®¡ç†æ™ºèƒ½ä½“"
    """
    
    iteration_num = state.get("total_iterations", 0)
    print(f"\nğŸ¯ [Coordinator Agent] ç¬¬{iteration_num}è½®åè°ƒ...")
    
    try:
        llm = get_llm(config)
        llm_with_structure = llm.with_structured_output(CoordinatorDecision)
        
        # æ„å»ºåè°ƒä¸Šä¸‹æ–‡
        current_phase = state.get("current_phase", "start")
        verification_output = state.get("verification_output")
        comprehension_output = state.get("comprehension_output")
        planning_output = state.get("planning_output")
        execution_output = state.get("execution_output")
        
        # æ„å»ºçŠ¶æ€æ‘˜è¦
        status_summary = f"""
ã€å½“å‰è¿­ä»£ã€‘ç¬¬ {iteration_num} è½®

ã€åŸå§‹é—®é¢˜ã€‘
{state.get('user_input')}

ã€å½“å‰é˜¶æ®µã€‘{current_phase}

ã€å·²å®Œæˆçš„å·¥ä½œã€‘
"""
        
        if comprehension_output:
            status_summary += f"""
- âœ… é¢˜ç›®ç†è§£å®Œæˆ
  - é—®é¢˜ç±»å‹: {comprehension_output.problem_type}
  - æ ¸å¿ƒé¢†åŸŸ: {comprehension_output.primary_field}
  - æ±‚è§£ç›®æ ‡: {', '.join(comprehension_output.objectives[:2])}...
"""
        
        if planning_output:
            status_summary += f"""
- âœ… ç­–ç•¥è§„åˆ’å®Œæˆ
  - ç”Ÿæˆäº† {len(planning_output.execution_tasks)} ä¸ªæ‰§è¡Œä»»åŠ¡
"""
        
        if execution_output:
            status_summary += f"""
- âœ… è®¡ç®—æ‰§è¡Œå®Œæˆ
  - æ‰§è¡Œäº† {len(execution_output.tool_executions)} ä¸ªå·¥å…·è°ƒç”¨
  - æœ€ç»ˆç»“æœ: {str(execution_output.final_result)[:100]}...
"""
        
        # å¦‚æœæœ‰éªŒè¯åé¦ˆï¼Œè¿™æ˜¯æœ€å…³é”®çš„ä¿¡æ¯
        if verification_output:
            status_summary += f"""

ã€éªŒè¯åé¦ˆã€‘ï¼ˆæœ€é‡è¦ï¼ï¼‰
- éªŒè¯çŠ¶æ€: {verification_output.status.value}
- ç½®ä¿¡åº¦: {verification_output.confidence_score}

å‘ç°çš„é—®é¢˜ï¼š
"""
            for i, issue in enumerate(verification_output.issues, 1):
                status_summary += f"{i}. [{issue.issue_type.value}] {issue.detail}\n"
            
            if verification_output.suggestions:
                status_summary += f"\næ”¹è¿›å»ºè®®ï¼š\n"
                for i, suggestion in enumerate(verification_output.suggestions, 1):
                    status_summary += f"{i}. {suggestion}\n"
            
            status_summary += f"\nè£å†³ç†ç”±ï¼š\n{verification_output.rationale}\n"
        
        # è¿­ä»£å†å²
        if state.get("iteration_history"):
            status_summary += f"\nã€è¿­ä»£å†å²ã€‘\n"
            for record in state["iteration_history"][-3:]:  # æœ€è¿‘3æ¬¡
                status_summary += f"- è¿­ä»£{record.iteration_number}: {record.phase} â†’ {record.actions_taken}\n"
        
        # é™åˆ¶æ¡ä»¶
        max_iterations = state.get("max_iterations", 10)
        status_summary += f"""

ã€é™åˆ¶æ¡ä»¶ã€‘
- æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}
- å½“å‰è¿­ä»£: {iteration_num}
- å‰©ä½™è¿­ä»£: {max_iterations - iteration_num}
"""
        
        # æ„å»ºå†³ç­–æç¤ºè¯
        decision_prompt = f"""
{COORDINATOR_PROMPT}

{status_summary}

---

ç°åœ¨è¯·ä½ ä½œä¸ºåè°ƒç®¡ç†æ™ºèƒ½ä½“ï¼Œåˆ†æå½“å‰æƒ…å†µå¹¶åšå‡ºå†³ç­–ï¼š

1. **å¦‚æœéªŒè¯çŠ¶æ€æ˜¯PASSED**ï¼š
   - next_action: "complete"
   - ç†ç”±ï¼šéªŒè¯é€šè¿‡ï¼Œå¯ä»¥äº¤ä»˜æœ€ç»ˆç»“æœ

2. **å¦‚æœéªŒè¯çŠ¶æ€æ˜¯NEEDS_REVISION**ï¼š
   - ä»”ç»†åˆ†æé—®é¢˜åˆ—è¡¨å’Œæ”¹è¿›å»ºè®®
   - åˆ¤æ–­é—®é¢˜æ ¹æºåœ¨å“ªä¸ªå±‚é¢ï¼š
     * ç†è§£å±‚é¢çš„æ ¹æœ¬åå·®ï¼ˆæç½•è§ï¼‰ â†’ next_action: "comprehension"
     * è§„åˆ’å±‚é¢çš„ç­–ç•¥é—®é¢˜ï¼ˆè®¡åˆ’æ­¥éª¤ç¼ºå¤±ã€æ–¹æ³•ä¸å½“ï¼‰ â†’ next_action: "planning"
     * æ‰§è¡Œå±‚é¢çš„å°é”™ï¼ˆè®¡ç®—é”™è¯¯ã€æ ¼å¼é—®é¢˜ï¼‰ â†’ next_action: "execution"
   - ç»™å‡ºæ¸…æ™°çš„reasoningå’Œå…·ä½“çš„instructions

3. **å¦‚æœéªŒè¯çŠ¶æ€æ˜¯FATAL_ERROR**ï¼š
   - next_action: "complete"
   - ç†ç”±ï¼šè‡´å‘½é”™è¯¯ï¼Œæ— æ³•ç»§ç»­

4. **å¦‚æœè¿˜æ²¡æœ‰éªŒè¯ç»“æœ**ï¼š
   - æ ¹æ®å½“å‰é˜¶æ®µå†³å®šä¸‹ä¸€æ­¥
   - é€šå¸¸é¡ºåºæ˜¯ï¼šcomprehension â†’ planning â†’ execution â†’ verification

5. **å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°**ï¼š
   - should_continue: false
   - next_action: "complete"
   - ç†ç”±ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£é™åˆ¶

è¯·è¿”å›ä½ çš„å†³ç­–ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{{
    "next_action": "comprehension/planning/execution/verification/complete",
    "reasoning": "è¯¦ç»†çš„å†³ç­–ç†ç”±",
    "instructions": "ç»™ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“çš„å…·ä½“æŒ‡ä»¤",
    "should_continue": true/false
}}
        """
        
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„åè°ƒç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£æ™ºèƒ½å†³ç­–æ•´ä¸ªè§£é¢˜æµç¨‹ã€‚"),
            HumanMessage(content=decision_prompt)
        ]
        
        # è°ƒç”¨LLMåšå†³ç­–
        decision = llm_with_structure.invoke(messages)
        
        # æ‰“å°å†³ç­–
        print(f"\n  ğŸ“Š Coordinatorå†³ç­–ï¼š")
        print(f"     ä¸‹ä¸€æ­¥: {decision.next_action}")
        print(f"     ç†ç”±: {decision.reasoning}")
        print(f"     æŒ‡ä»¤: {decision.instructions[:100]}...")
        print(f"     ç»§ç»­: {decision.should_continue}")
        
        # âœ… å¦‚æœå†³å®šcompleteï¼Œå¹¶ä¸”éªŒè¯é€šè¿‡ï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        if decision.next_action == "complete" and verification_output and verification_output.status == VerificationStatus.PASSED:
            print(f"\n  ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
            final_answer = _generate_final_report(state, config)
            
            return {
                "current_phase": "complete",
                "final_answer": final_answer,
                "needs_retry": False,
                "messages": [AIMessage(content=f"âœ… è§£é¢˜å®Œæˆï¼Coordinatorå·²ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")]
            }
        
        # å…¶ä»–æƒ…å†µï¼šæ­£å¸¸è·¯ç”±
        return {
            "current_phase": decision.next_action,
            "needs_retry": decision.should_continue and decision.next_action != "complete",
            "messages": [AIMessage(content=f"Coordinatorå†³ç­–ï¼š{decision.reasoning}")]
        }
    
    except Exception as e:
        print(f"âŒ [Coordinator Agent] é”™è¯¯: {e}")
        # å‡ºé”™æ—¶é»˜è®¤å®Œæˆ
        return {
            "current_phase": "complete",
            "error_message": f"Coordinatorå†³ç­–å¤±è´¥: {str(e)}",
            "needs_retry": False
        }


###################
# é¢˜ç›®ç†è§£æ™ºèƒ½ä½“ï¼ˆComprehension Agentï¼‰
###################

def comprehension_agent(state: AgentState, config: Optional[Configuration] = None) -> AgentState:
    """
    é¢˜ç›®ç†è§£æ™ºèƒ½ä½“èŠ‚ç‚¹
    
    ä»»åŠ¡ï¼š
    1. LaTeXæ ‡å‡†åŒ–
    2. é—®é¢˜è¡¨è±¡è§£æ„ï¼ˆå·²çŸ¥ã€ç›®æ ‡ã€çº¦æŸï¼‰
    3. æ ¸å¿ƒåŸç†æº¯æº
    4. ç­–ç•¥è·¯å¾„æ„å»º
    
    è¾“å…¥ï¼šstate.user_input
    è¾“å‡ºï¼šstate.comprehension_output
    """
    
    print("ğŸ§  [Comprehension Agent] å¼€å§‹åˆ†æé¢˜ç›®...")
    
    try:
        llm = get_llm(config)
        
        # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
        llm_with_structure = llm.with_structured_output(ComprehensionOutput)
        
        # æ„å»ºæç¤ºè¯
        prompt = COMPREHENSION_PROMPT.format(user_input=state["user_input"])
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä½é¡¶å°–çš„æ•°å­¦é—®é¢˜åˆ†æä¸“å®¶ã€‚"),
            HumanMessage(content=prompt)
        ]
        
        # è°ƒç”¨LLM
        comprehension_output = llm_with_structure.invoke(messages)
        
        # âœ… åªè¿”å›ç†è§£ç»“æœï¼Œä¸è®¾ç½®current_phase
        # ç”±Coordinatorå†³å®šä¸‹ä¸€æ­¥
        return {
            "comprehension_output": comprehension_output,
            # âŒ ä¸è®¾ç½®current_phaseï¼Œè®©Coordinatorçš„LLMå†³ç­–
            "messages": [AIMessage(content=f"é¢˜ç›®ç†è§£å®Œæˆï¼š{comprehension_output.normalized_latex}")]
        }
    
    except Exception as e:
        print(f"âŒ [Comprehension Agent] é”™è¯¯: {e}")
        return {
            "error_message": f"é¢˜ç›®ç†è§£å¤±è´¥: {str(e)}",
            "needs_retry": True
        }


###################
# ç­–ç•¥è§„åˆ’æ™ºèƒ½ä½“ï¼ˆPlanning Agentï¼‰
###################

def planning_agent(state: AgentState, config: Optional[Configuration] = None) -> AgentState:
    """
    ç­–ç•¥è§„åˆ’æ™ºèƒ½ä½“èŠ‚ç‚¹ï¼ˆagent.md: æ‰§è¡Œæ ¸å¿ƒä¹‹ä¸€ï¼‰
    
    ä»»åŠ¡ï¼š
    1. åŸºäºç†è§£ç»“æœåˆ¶å®šæ‰§è¡Œè®¡åˆ’
    2. åˆ†è§£ä¸ºåŸå­ä»»åŠ¡ï¼ˆDAGç»“æ„ï¼‰
    3. é“¾æ¥åˆ°åŸºç¡€åŸç†
    4. å®šä¹‰ä»»åŠ¡ä¾èµ–å…³ç³»
    5. å¤„ç†éªŒè¯åé¦ˆï¼Œä¼˜åŒ–æˆ–é‡å†™è®¡åˆ’
    
    è¾“å…¥ï¼šstate.comprehension_output, state.verification_output (å¯é€‰)
    è¾“å‡ºï¼šstate.planning_output
    """
    
    iteration_num = state.get("total_iterations", 0) + 1
    verification_feedback = state.get("verification_output")
    
    if verification_feedback:
        print(f"ğŸ“‹ [Planning Agent] ç¬¬{iteration_num}è½®è§„åˆ’ï¼ˆåŸºäºéªŒè¯åé¦ˆï¼‰...")
    else:
        print(f"ğŸ“‹ [Planning Agent] ç¬¬{iteration_num}è½®è§„åˆ’ï¼ˆé¦–æ¬¡ï¼‰...")
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not state.get("comprehension_output"):
        return {
            "error_message": "ç¼ºå°‘é¢˜ç›®ç†è§£ç»“æœï¼Œæ— æ³•è¿›è¡Œè§„åˆ’",
            "needs_retry": False
        }
    
    try:
        llm = get_llm(config)
        llm_with_structure = llm.with_structured_output(PlanningOutput)
        
        # æ„å»ºæç¤ºè¯
        comprehension_result = state["comprehension_output"]
        analysis_summary = f"""
é—®é¢˜ç±»å‹ï¼š{comprehension_result.problem_type}
æ ¸å¿ƒé¢†åŸŸï¼š{comprehension_result.primary_field}
å·²çŸ¥ä¿¡æ¯ï¼š{', '.join(comprehension_result.givens)}
æ±‚è§£ç›®æ ‡ï¼š{', '.join(comprehension_result.objectives)}
ç­–ç•¥æ¨æ¼”ï¼š{comprehension_result.strategy_deduction}
        """
        
        # å¦‚æœæœ‰éªŒè¯åé¦ˆï¼Œæ·»åŠ æ”¹è¿›æŒ‡å¯¼
        if verification_feedback and verification_feedback.suggestions:
            print("  â†’ å¤„ç†éªŒè¯åé¦ˆï¼Œä¼˜åŒ–è®¡åˆ’...")
            for i, suggestion in enumerate(verification_feedback.suggestions, 1):
                print(f"    {i}. {suggestion}")
            
            improvement_guidance = f"""

ã€éªŒè¯åé¦ˆã€‘
å‘ç°é—®é¢˜ï¼š
{chr(10).join(f"- {issue.issue_type.value}: {issue.detail}" for issue in verification_feedback.issues)}

æ”¹è¿›å»ºè®®ï¼š
{chr(10).join(f"- {sugg}" for sugg in verification_feedback.suggestions)}

è¯·æ ¹æ®ä¸Šè¿°åé¦ˆï¼Œä¼˜åŒ–æˆ–é‡å†™æ‰§è¡Œè®¡åˆ’ï¼Œç¡®ä¿ï¼š
1. è§£å†³æ‰€æœ‰æŒ‡å‡ºçš„é—®é¢˜
2. éµå¾ªæ‰€æœ‰æ”¹è¿›å»ºè®®
3. ä¿æŒè®¡åˆ’çš„åŸå­æ€§å’Œç¡®å®šæ€§
            """
            analysis_summary += improvement_guidance
        
        prompt = PREPROCESSING_PROMPT.format(math_problem_analysis=analysis_summary)
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä½é¡¶å°–çš„è®¡ç®—ç­–ç•¥è§„åˆ’å¸ˆã€‚"),
            HumanMessage(content=prompt)
        ]
        
        # è°ƒç”¨LLM
        planning_output = llm_with_structure.invoke(messages)
        
        print(f"  âœ“ è§„åˆ’å®Œæˆï¼šç”Ÿæˆ {len(planning_output.execution_tasks)} ä¸ªä»»åŠ¡")
        
        # è®°å½•è¿­ä»£
        iteration_update = add_iteration_record(
            state,
            phase="planning",
            result_version=f"Plan_v{iteration_num}",
            verification_status=None,
            issues_found=[],
            actions_taken=f"ç”Ÿæˆ{len(planning_output.execution_tasks)}ä¸ªæ‰§è¡Œä»»åŠ¡"
        )
        
        # âœ… åªè¿”å›è§„åˆ’ç»“æœï¼Œä¸è®¾ç½®current_phase
        # ç”±Coordinatorå†³å®šä¸‹ä¸€æ­¥
        return {
            **iteration_update,
            "planning_output": planning_output,
            # âŒ ä¸è®¾ç½®current_phaseï¼Œè®©Coordinatorçš„LLMå†³ç­–
            "messages": [AIMessage(content=f"è§„åˆ’å®Œæˆï¼šç”Ÿæˆäº† {len(planning_output.execution_tasks)} ä¸ªæ‰§è¡Œä»»åŠ¡")]
        }
    
    except Exception as e:
        print(f"âŒ [Planning Agent] é”™è¯¯: {e}")
        return {
            "error_message": f"ç­–ç•¥è§„åˆ’å¤±è´¥: {str(e)}",
            "needs_retry": True
        }


###################
# è®¡ç®—æ‰§è¡Œæ™ºèƒ½ä½“ï¼ˆExecution Agentï¼‰
###################

def execution_agent(state: AgentState, config: Optional[Configuration] = None) -> AgentState:
    """
    è®¡ç®—æ‰§è¡Œæ™ºèƒ½ä½“èŠ‚ç‚¹ï¼ˆagent.md: æ‰§è¡Œæ ¸å¿ƒä¹‹ä¸€ï¼‰
    
    ä»»åŠ¡ï¼š
    1. æŒ‰ç…§è®¡åˆ’æ‰§è¡Œæ¯ä¸ªä»»åŠ¡
    2. é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼ˆSymPy/Wolfram Alpha/Internal Reasoningï¼‰
    3. è®°å½•è®¡ç®—è½¨è¿¹
    4. ç®¡ç†å·¥ä½œåŒºå˜é‡
    5. å¤„ç†éªŒè¯åé¦ˆï¼Œä¿®æ­£æ‰§è¡Œé”™è¯¯
    
    ä½¿ç”¨prompt.pyä¸­ç²¾å¿ƒè®¾è®¡çš„EXECUTION_PROMPT
    
    è¾“å…¥ï¼šstate.planning_output, state.verification_output (å¯é€‰)
    è¾“å‡ºï¼šstate.execution_output
    """
    
    iteration_num = state.get("total_iterations", 0) + 1
    verification_feedback = state.get("verification_output")
    
    if verification_feedback:
        print(f"âš™ï¸ [Execution Agent] ç¬¬{iteration_num}è½®æ‰§è¡Œï¼ˆåŸºäºéªŒè¯åé¦ˆï¼‰...")
    else:
        print(f"âš™ï¸ [Execution Agent] ç¬¬{iteration_num}è½®æ‰§è¡Œï¼ˆé¦–æ¬¡ï¼‰...")
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not state.get("planning_output"):
        return {
            "error_message": "ç¼ºå°‘æ‰§è¡Œè®¡åˆ’ï¼Œæ— æ³•æ‰§è¡Œ",
            "needs_retry": False
        }
    
    try:
        llm = get_llm(config)
        
        planning_output = state["planning_output"]
        workspace = {}
        tool_executions = []
        computational_trace = []
        
        # å¦‚æœæœ‰éªŒè¯åé¦ˆï¼Œæ˜¾ç¤ºä¿®æ­£æŒ‡å¯¼
        feedback_context = ""
        if verification_feedback and verification_feedback.suggestions:
            print("  â†’ å¤„ç†éªŒè¯åé¦ˆï¼Œä¿®æ­£æ‰§è¡Œ...")
            for i, suggestion in enumerate(verification_feedback.suggestions, 1):
                print(f"    {i}. {suggestion}")
            
            feedback_context = f"""

ã€éªŒè¯åé¦ˆä¿®æ­£æŒ‡å¯¼ã€‘
å‘ç°çš„é—®é¢˜ï¼š
{chr(10).join(f"- {issue.issue_type.value}: {issue.detail}" for issue in verification_feedback.issues)}

æ”¹è¿›å»ºè®®ï¼ˆå¿…é¡»éµå¾ªï¼‰ï¼š
{chr(10).join(f"- {sugg}" for sugg in verification_feedback.suggestions)}

è¯·åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ç‰¹åˆ«æ³¨æ„è¿™äº›åé¦ˆï¼Œç¡®ä¿ä¿®æ­£æ‰€æœ‰é—®é¢˜ã€‚
            """
        
        # æ„å»ºå®Œæ•´çš„æ‰§è¡Œæç¤ºè¯ï¼ˆä½¿ç”¨ç²¾å¿ƒè®¾è®¡çš„EXECUTION_PROMPTï¼‰
        preprocessing_plan_json = planning_output.model_dump_json(indent=2)
        
        full_execution_prompt = EXECUTION_PROMPT.format(
            preprocessing_plan=preprocessing_plan_json
        ) + feedback_context
        
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“å®¶çº§çš„è®¡ç®—æ•°å­¦å®¶ï¼Œç²¾é€šSymPyå’ŒWolfram Alphaç­‰è®¡ç®—å·¥å…·ã€‚"),
            HumanMessage(content=full_execution_prompt)
        ]
        
        # è°ƒç”¨LLMæ‰§è¡Œï¼ˆç®€åŒ–ç‰ˆæœ¬ - å®é™…åº”è¯¥è§£æLLMçš„ç»“æ„åŒ–è¾“å‡ºï¼‰
        response = llm.invoke(messages)
        
        print(f"  âœ“ LLMæ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨è§£æç»“æœ...")
        
        # åˆå§‹åŒ–å·¥ä½œåŒº
        for var in planning_output.workspace_init:
            workspace[var["variable_name"]] = var.get("value_ref", None)
            computational_trace.append(f"åˆå§‹åŒ–å˜é‡ {var['variable_name']}")
        
        # æ‰§è¡Œä»»åŠ¡ï¼ˆâœ… LLMæ™ºèƒ½é€‰æ‹©å·¥å…·ï¼‰
        for task in planning_output.execution_tasks:
            print(f"  â†’ æ‰§è¡Œä»»åŠ¡ {task.task_id}: {task.description}")
            
            # âœ… LLMæ™ºèƒ½é€‰æ‹©å¹¶è°ƒç”¨å·¥å…·
            tool_result = _execute_tool_call(task, response.content, workspace, config)
            
            tool_executions.append(tool_result)
            computational_trace.append(f"ä»»åŠ¡ {task.task_id} å®Œæˆï¼Œè¾“å‡ºä¿å­˜åˆ° {task.output_id}")
            
            # æ›´æ–°å·¥ä½œåŒº
            workspace[task.output_id] = tool_result.tool_output
        
        # æ„å»ºæ‰§è¡Œè¾“å‡º
        execution_output = ExecutionOutput(
            workspace=workspace,
            tool_executions=tool_executions,
            computational_trace=computational_trace,
            final_result=workspace.get("final_result")
        )
        
        print(f"  âœ“ æ‰§è¡Œå®Œæˆï¼š{len(tool_executions)}ä¸ªå·¥å…·è°ƒç”¨")
        
        # è®°å½•è¿­ä»£
        iteration_update = add_iteration_record(
            state,
            phase="execution",
            result_version=f"Result_v{iteration_num}",
            verification_status=None,
            issues_found=[],
            actions_taken=f"æ‰§è¡Œ{len(tool_executions)}ä¸ªå·¥å…·è°ƒç”¨"
        )
        
        # âœ… åªè¿”å›æ‰§è¡Œç»“æœï¼Œä¸è®¾ç½®current_phase
        # ç”±Coordinatorå†³å®šä¸‹ä¸€æ­¥
        return {
            **iteration_update,
            "execution_output": execution_output,
            # âŒ ä¸è®¾ç½®current_phaseï¼Œè®©Coordinatorçš„LLMå†³ç­–
            "messages": [AIMessage(content=f"æ‰§è¡Œå®Œæˆï¼šå…±æ‰§è¡Œ {len(tool_executions)} ä¸ªå·¥å…·è°ƒç”¨")]
        }
    
    except Exception as e:
        print(f"âŒ [Execution Agent] é”™è¯¯: {e}")
        return {
            "error_message": f"è®¡ç®—æ‰§è¡Œå¤±è´¥: {str(e)}",
            "needs_retry": True
        }


def _execute_tool_call(task, llm_response: str, workspace: dict, config: Optional[Configuration] = None) -> ToolExecutionRecord:
    """
    æ‰§è¡Œå®é™…çš„å·¥å…·è°ƒç”¨ï¼ˆè¾…åŠ©å‡½æ•°ï¼‰
    
    âœ… ä½¿ç”¨LLMæ™ºèƒ½å†³ç­–å·¥å…·é€‰æ‹©ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç å…³é”®è¯åŒ¹é…
    
    å·¥å…·é€‰é¡¹ï¼š
    1. SymPyï¼šç¬¦å·è®¡ç®—ã€ä»£æ•°ã€å¾®ç§¯åˆ†ã€æ–¹ç¨‹æ±‚è§£
    2. Wolfram Alphaï¼šå¤æ‚è®¡ç®—ã€æ•°å€¼è®¡ç®—ã€æ•°æ®æŸ¥è¯¢
    3. Internal Reasoningï¼šé€»è¾‘æ¨ç†ã€æ ¼å¼åŒ–ã€ç®€å•è¿ç®—
    """
    
    try:
        # âœ… ä½¿ç”¨LLMåšå·¥å…·é€‰æ‹©å†³ç­–
        llm = get_llm(config)
        llm_with_structure = llm.with_structured_output(ToolSelectionDecision)
        
        # æ„å»ºå·¥å…·é€‰æ‹©æç¤ºè¯
        tool_selection_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å·¥å…·é€‰æ‹©ä¸“å®¶ã€‚ä½ éœ€è¦åˆ†æä»»åŠ¡å¹¶é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚

ã€ä»»åŠ¡ä¿¡æ¯ã€‘
ä»»åŠ¡ID: {task.task_id}
ä»»åŠ¡æè¿°: {task.description}
æ–¹æ³•: {task.method if hasattr(task, 'method') else 'æœªæŒ‡å®š'}
å‚æ•°: {task.params if hasattr(task, 'params') else {}}

ã€å¯ç”¨å·¥å…·ã€‘

1. **SymPy** (ç¬¦å·è®¡ç®—åº“)
   - é€‚ç”¨åœºæ™¯ï¼š
     * ç²¾ç¡®çš„ä»£æ•°è¿ç®—ï¼ˆæ–¹ç¨‹æ±‚è§£ã€ç®€åŒ–ã€å› å¼åˆ†è§£ã€å±•å¼€ï¼‰
     * å¾®ç§¯åˆ†ï¼ˆå¯¼æ•°ã€ç§¯åˆ†ã€æé™ã€çº§æ•°å±•å¼€ï¼‰
     * çº¿æ€§ä»£æ•°ï¼ˆçŸ©é˜µè¿ç®—ã€ç‰¹å¾å€¼ã€è¡Œåˆ—å¼ï¼‰
     * å¾®åˆ†æ–¹ç¨‹æ±‚è§£
     * æ•°è®ºè¿ç®—ï¼ˆè´¨æ•°ã€æœ€å¤§å…¬çº¦æ•°ã€å› æ•°åˆ†è§£ï¼‰
     * ç¬¦å·è¡¨è¾¾å¼å¤„ç†
   - ä¼˜åŠ¿ï¼šç²¾ç¡®çš„ç¬¦å·è®¡ç®—ï¼Œå®Œæ•´çš„æ¨å¯¼æ­¥éª¤
   - ç¤ºä¾‹ï¼šæ±‚è§£æ–¹ç¨‹ x^2 + 2x + 1 = 0ï¼Œæ±‚å¯¼æ•° d/dx(sin(x))

2. **Wolfram Alpha** (è®¡ç®—çŸ¥è¯†å¼•æ“)
   - é€‚ç”¨åœºæ™¯ï¼š
     * å¤æ‚çš„æ•°å€¼è®¡ç®—
     * éœ€è¦å¤–éƒ¨çŸ¥è¯†çš„è®¡ç®—ï¼ˆç‰©ç†å¸¸æ•°ã€å•ä½è½¬æ¢ï¼‰
     * ç»Ÿè®¡åˆ†æã€æ•°æ®æŸ¥è¯¢
     * å½“SymPyæ— æ³•å¤„ç†çš„å¤æ‚é—®é¢˜
   - ä¼˜åŠ¿ï¼šå¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ï¼Œä¸°å¯Œçš„çŸ¥è¯†åº“
   - æ³¨æ„ï¼šéœ€è¦APIè°ƒç”¨ï¼Œå¯èƒ½è¾ƒæ…¢

3. **Internal Reasoning** (å†…éƒ¨æ¨ç†)
   - é€‚ç”¨åœºæ™¯ï¼š
     * ç®€å•çš„é€»è¾‘æ¨ç†
     * æ ¼å¼åŒ–è¾“å‡º
     * å·¥ä½œåŒºå˜é‡ç®¡ç†
     * ä¸éœ€è¦å¤æ‚è®¡ç®—çš„ä»»åŠ¡
   - ä¼˜åŠ¿ï¼šå¿«é€Ÿï¼Œæ— éœ€å¤–éƒ¨è°ƒç”¨

ã€å·¥ä½œåŒºçŠ¶æ€ã€‘
å½“å‰å·¥ä½œåŒºå˜é‡: {list(workspace.keys()) if workspace else 'ç©º'}

---

è¯·åˆ†æä¸Šè¿°ä»»åŠ¡ï¼Œå¹¶é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚è€ƒè™‘å› ç´ ï¼š
1. ä»»åŠ¡çš„æ€§è´¨ï¼ˆä»£æ•°/å¾®ç§¯åˆ†/æ•°å€¼/é€»è¾‘ï¼‰
2. æ‰€éœ€çš„ç²¾åº¦ï¼ˆç¬¦å·vsæ•°å€¼ï¼‰
3. è®¡ç®—çš„å¤æ‚åº¦
4. æ˜¯å¦éœ€è¦å¤–éƒ¨çŸ¥è¯†

è¿”å›ä½ çš„å†³ç­–ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{{
    "tool_name": "sympy/wolfram_alpha/internal_reasoning",
    "reasoning": "è¯¦ç»†çš„é€‰æ‹©ç†ç”±",
    "confidence": 0.0-1.0
}}
        """
        
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å·¥å…·é€‰æ‹©ä¸“å®¶ï¼Œæ“…é•¿åˆ†æä»»åŠ¡å¹¶é€‰æ‹©æœ€åˆé€‚çš„è®¡ç®—å·¥å…·ã€‚"),
            HumanMessage(content=tool_selection_prompt)
        ]
        
        # è°ƒç”¨LLMåšå†³ç­–
        decision = llm_with_structure.invoke(messages)
        
        print(f"    ğŸ¤– LLMå·¥å…·é€‰æ‹©: {decision.tool_name}")
        print(f"       ç†ç”±: {decision.reasoning}")
        print(f"       ç½®ä¿¡åº¦: {decision.confidence}")
        
        # âœ… æ ¹æ®LLMçš„å†³ç­–è°ƒç”¨ç›¸åº”çš„å·¥å…·
        if decision.tool_name.lower() == "sympy":
            tool_type = ToolType.SYMPY
            tool_result = _call_sympy_tool(task, workspace)
            
        elif decision.tool_name.lower() == "wolfram_alpha":
            tool_type = ToolType.WOLFRAM_ALPHA
            tool_result = _call_wolfram_tool(task, workspace)
            
        else:  # internal_reasoning
            tool_type = ToolType.INTERNAL_REASONING
            tool_result = _call_internal_reasoning(task, workspace)
        
        return ToolExecutionRecord(
            task_id=task.task_id,
            tool_type=tool_type,
            tool_input=task.description,
            tool_output=tool_result,
            rationale=f"LLMé€‰æ‹©: {decision.reasoning} (ç½®ä¿¡åº¦: {decision.confidence})"
        )
        
    except Exception as e:
        print(f"    âš ï¸ LLMå·¥å…·é€‰æ‹©å¤±è´¥: {e}ï¼Œå›é€€åˆ°å†…éƒ¨æ¨ç†")
        # å‡ºé”™æ—¶å›é€€åˆ°å†…éƒ¨æ¨ç†
        tool_result = _call_internal_reasoning(task, workspace)
        return ToolExecutionRecord(
            task_id=task.task_id,
            tool_type=ToolType.INTERNAL_REASONING,
            tool_input=task.description,
            tool_output=tool_result,
            rationale=f"LLMå†³ç­–å¤±è´¥ï¼Œå›é€€åˆ°å†…éƒ¨æ¨ç†: {str(e)}"
        )


def _call_sympy_tool(task, workspace: dict) -> str:
    """
    è°ƒç”¨SymPyå·¥å…·æ‰§è¡Œç¬¦å·è®¡ç®—
    """
    try:
        # åˆ›å»ºSymPyå·¥å…·å®ä¾‹
        tool = create_sympy_tool()
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒç”¨ç›¸åº”çš„æ–¹æ³•
        params = task.params if hasattr(task, 'params') else {}
        method_lower = task.method.lower() if hasattr(task, 'method') else ""
        
        if 'solve' in method_lower and 'equation' in method_lower:
            # æ±‚è§£æ–¹ç¨‹
            equation = params.get('equation', task.description)
            variable = params.get('variable', 'x')
            result = tool.solve_equation(equation, variable)
            
        elif 'simplify' in method_lower:
            # ç®€åŒ–è¡¨è¾¾å¼
            expression = params.get('expression', task.description)
            result = tool.simplify_expression(expression)
            
        elif 'differentiate' in method_lower or 'derivative' in method_lower:
            # å¾®åˆ†
            expression = params.get('expression', task.description)
            variable = params.get('variable', 'x')
            order = params.get('order', 1)
            result = tool.differentiate(expression, variable, order)
            
        elif 'integrate' in method_lower or 'integral' in method_lower:
            # ç§¯åˆ†
            expression = params.get('expression', task.description)
            variable = params.get('variable', 'x')
            limits = params.get('limits', None)
            result = tool.integrate(expression, variable, limits)
            
        else:
            # é€šç”¨æ±‚è§£
            result = tool.solve_math_problem(task.description)
        
        # æ ¼å¼åŒ–è¾“å‡º
        if result.get('success'):
            output = f"SymPyè®¡ç®—ç»“æœï¼š{result.get('result', result.get('solution', result.get('simplified', 'N/A')))}"
            if result.get('latex'):
                output += f"\nLaTeX: {result['latex']}"
            return output
        else:
            return f"SymPyè®¡ç®—å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
    except Exception as e:
        return f"SymPyå·¥å…·è°ƒç”¨é”™è¯¯ï¼š{str(e)}"


def _call_wolfram_tool(task, workspace: dict) -> str:
    """
    è°ƒç”¨Wolfram Alphaå·¥å…·æ‰§è¡Œè®¡ç®—
    """
    try:
        # åˆ›å»ºWolfram Alphaå·¥å…·å®ä¾‹
        tool = create_wolfram_alpha_tool()
        
        # è°ƒç”¨Wolfram Alphaæ±‚è§£
        result = tool.solve_math_problem(task.description)
        
        # æ ¼å¼åŒ–è¾“å‡º
        if result.get('success'):
            output = "Wolfram Alphaè®¡ç®—ç»“æœï¼š\n"
            if result.get('final_answer'):
                output += f"æœ€ç»ˆç­”æ¡ˆï¼š{result['final_answer']}\n"
            if result.get('steps'):
                output += "æ­¥éª¤ï¼š\n"
                for step in result['steps']:
                    output += f"  - {step['title']}: {step['content']}\n"
            return output
        else:
            return f"Wolfram Alphaè®¡ç®—å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
    except Exception as e:
        return f"Wolfram Alphaå·¥å…·è°ƒç”¨é”™è¯¯ï¼š{str(e)}"


def _call_internal_reasoning(task, workspace: dict) -> str:
    """
    ä½¿ç”¨å†…éƒ¨é€»è¾‘æ¨ç†ï¼ˆä¸è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼‰
    """
    # ç®€å•çš„å†…éƒ¨æ¨ç†ï¼Œå¯ä»¥å¤„ç†ï¼š
    # 1. ä»å·¥ä½œåŒºè·å–å˜é‡
    # 2. ç®€å•çš„é€»è¾‘åˆ¤æ–­
    # 3. æ ¼å¼åŒ–è¾“å‡º
    
    try:
        # å¦‚æœä»»åŠ¡éœ€è¦ä»å·¥ä½œåŒºè·å–å€¼
        if hasattr(task, 'params') and task.params:
            params = task.params
            if isinstance(params, dict):
                # æ›¿æ¢å·¥ä½œåŒºå¼•ç”¨
                for key, value in params.items():
                    if isinstance(value, str) and value in workspace:
                        params[key] = workspace[value]
        
        # æ‰§è¡Œç®€å•çš„é€»è¾‘æ“ä½œ
        return f"å†…éƒ¨æ¨ç†å®Œæˆï¼š{task.description}"
        
    except Exception as e:
        return f"å†…éƒ¨æ¨ç†é”™è¯¯ï¼š{str(e)}"


###################
# éªŒè¯åæ€æ™ºèƒ½ä½“ï¼ˆVerification Agentï¼‰
###################

def verification_agent(state: AgentState, config: Optional[Configuration] = None) -> AgentState:
    """
    éªŒè¯åæ€æ™ºèƒ½ä½“èŠ‚ç‚¹ï¼ˆagent.md: è¿­ä»£æ¨¡å¼çš„çµé­‚ï¼‰
    
    ä»»åŠ¡ï¼š
    1. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šï¼ˆVerification Reportï¼‰
    2. è¯„ä¼°çŠ¶æ€ï¼šPASSED / NEEDS_REVISION / FATAL_ERROR
    3. é—®é¢˜åˆ—è¡¨ï¼šæ¸…æ™°æŒ‡å‡ºé—®é¢˜ç±»å‹ï¼ˆFactual Error, Logical Flawç­‰ï¼‰
    4. ä¿®æ­£å»ºè®®ï¼šå…·ä½“å¯æ‰§è¡Œçš„ä¿®æ”¹æ„è§
    5. åˆ¤å®šé—®é¢˜å±‚çº§ï¼šå†³å®šè¿”å›å“ªä¸ªé˜¶æ®µ
    
    è¾“å…¥ï¼šstate.comprehension_output, state.execution_output
    è¾“å‡ºï¼šstate.verification_output
    """
    
    iteration_num = state.get("total_iterations", 0) + 1
    print(f"âœ… [Verification Agent] ç¬¬{iteration_num}è½®éªŒè¯...")
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not state.get("comprehension_output") or not state.get("execution_output"):
        return {
            "error_message": "ç¼ºå°‘ç†è§£ç»“æœæˆ–æ‰§è¡Œç»“æœï¼Œæ— æ³•éªŒè¯",
            "needs_retry": False
        }
    
    try:
        llm = get_llm(config)
        llm_with_structure = llm.with_structured_output(VerificationOutput)
        
        # æ„å»ºéªŒè¯è¾“å…¥ï¼ˆåŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
        comprehension = state["comprehension_output"]
        execution = state["execution_output"]
        planning = state.get("planning_output")
        
        # å‡†å¤‡VERIFICATION_PROMPTæ‰€éœ€çš„å‚æ•°
        analysis_report_json = comprehension.model_dump_json(indent=2)
        executor_report_json = execution.model_dump_json(indent=2)
        
        # ä½¿ç”¨ç²¾å¿ƒè®¾è®¡çš„VERIFICATION_PROMPT
        full_verification_prompt = VERIFICATION_PROMPT.format(
            analysis_report=analysis_report_json,
            executor_report=executor_report_json
        )
        
        # æ·»åŠ é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        additional_context = f"""

ã€è¡¥å……ä¸Šä¸‹æ–‡ã€‘
åŸå§‹é—®é¢˜ï¼š{state.get('user_input')}
æ‰§è¡Œè®¡åˆ’ï¼š
{planning.model_dump_json(indent=2) if planning else "æ— "}

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°éªŒè¯åè®®ç”Ÿæˆç»“æ„åŒ–çš„è¯Šæ–­æŠ¥å‘Šï¼ˆVerificationOutputï¼‰ï¼ŒåŒ…å«ï¼š
1. status: PASSED / NEEDS_REVISION / FATAL_ERROR
2. issues: å‘ç°çš„é—®é¢˜åˆ—è¡¨ï¼ˆæ¯ä¸ªé—®é¢˜åŒ…å«issue_typeå’Œdetailï¼‰
3. suggestions: å…·ä½“å¯æ‰§è¡Œçš„ä¿®æ”¹å»ºè®®
4. problem_level: execution / planning / comprehension
5. rationale: è£å†³ç†ç”±
6. confidence_score: 0-1ä¹‹é—´çš„ç½®ä¿¡åº¦
        """
        
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“å®¶çº§çš„æ•°å­¦é—®é¢˜éªŒè¯ä¸“å®¶ï¼Œç²¾é€šäº¤å‰éªŒè¯å’Œå®¡è®¡ã€‚"),
            HumanMessage(content=full_verification_prompt + additional_context)
        ]
        
        # è°ƒç”¨LLMç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        verification_output = llm_with_structure.invoke(messages)
        
        # è®°å½•æœ¬è½®è¿­ä»£
        result_version = f"Result_v{iteration_num}"
        issues_summary = [f"{issue.issue_type.value}: {issue.detail[:50]}..." 
                         for issue in verification_output.issues]
        
        # æ ¹æ®éªŒè¯ç»“æœè¿”å›è¯Šæ–­æŠ¥å‘Š
        if verification_output.status == VerificationStatus.PASSED:
            print(f"  âœ… éªŒè¯é€šè¿‡ï¼")
            print(f"  â†’ å°†éªŒè¯é€šè¿‡çš„æŠ¥å‘Šè¿”å›ç»™Coordinator...")
            
            # è®°å½•è¿­ä»£
            iteration_update = add_iteration_record(
                state,
                phase="verification",
                result_version=result_version,
                verification_status=VerificationStatus.PASSED,
                issues_found=[],
                actions_taken="éªŒè¯é€šè¿‡ï¼Œå»ºè®®Coordinatorå®Œæˆæµç¨‹"
            )
            
            # âœ… åªè¿”å›éªŒè¯æŠ¥å‘Šï¼Œä¸ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            # æœ€ç»ˆç­”æ¡ˆç”±Coordinatorç”Ÿæˆ
            return {
                **iteration_update,
                "verification_output": verification_output,
                # âŒ ä¸ç”Ÿæˆfinal_answerï¼Œè¿™æ˜¯Coordinatorçš„èŒè´£
                # ä¸è®¾ç½®current_phaseï¼Œè®©Coordinatorå†³ç­–
                "messages": [AIMessage(content="âœ… éªŒè¯é€šè¿‡ï¼Œç­‰å¾…Coordinatorç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")]
            }
        
        elif verification_output.status == VerificationStatus.NEEDS_REVISION:
            print(f"  âš ï¸ éœ€è¦ä¿®è®¢ï¼šå‘ç° {len(verification_output.issues)} ä¸ªé—®é¢˜")
            for issue in verification_output.issues:
                print(f"    - {issue.issue_type.value}: {issue.detail[:80]}")
            
            print(f"  â†’ è¯Šæ–­å®Œæˆï¼Œé—®é¢˜å±‚çº§ï¼š{verification_output.problem_level.value}")
            print(f"  â†’ å°†è¯Šæ–­æŠ¥å‘Šè¿”å›ç»™Coordinatorè¿›è¡Œæ™ºèƒ½å†³ç­–...")
            
            # è®°å½•è¿­ä»£ï¼ˆä¸åšå†³ç­–ï¼Œåªè®°å½•å‘ç°çš„é—®é¢˜ï¼‰
            iteration_update = add_iteration_record(
                state,
                phase="verification",
                result_version=result_version,
                verification_status=VerificationStatus.NEEDS_REVISION,
                issues_found=issues_summary,
                actions_taken=f"å‘ç°{len(verification_output.issues)}ä¸ªé—®é¢˜ï¼Œç­‰å¾…Coordinatorå†³ç­–"
            )
            
            # âœ… åªè¿”å›è¯Šæ–­æŠ¥å‘Šï¼Œä¸åšä»»ä½•å†³ç­–
            # âŒ ä¸è®¾ç½® current_phaseï¼ˆç”±Coordinatorå†³ç­–ï¼‰
            # âŒ ä¸åˆ¤æ–­é—®é¢˜æ ¹æºï¼ˆç”±Coordinatorçš„LLMæ™ºèƒ½åˆ†æï¼‰
            return {
                **iteration_update,
                "verification_output": verification_output,
                "needs_retry": True,
                "messages": [AIMessage(
                    content=f"âš ï¸ éªŒè¯å‘ç°{len(verification_output.issues)}ä¸ªé—®é¢˜ï¼Œå·²ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š\né—®é¢˜æ‘˜è¦ï¼š{'; '.join(issues_summary)}"
                )]
            }
        
        else:  # FATAL_ERROR
            print(f"  âŒ è‡´å‘½é”™è¯¯")
            print(f"  â†’ å°†è‡´å‘½é”™è¯¯æŠ¥å‘Šè¿”å›ç»™Coordinator...")
            
            # è®°å½•è¿­ä»£
            iteration_update = add_iteration_record(
                state,
                phase="verification",
                result_version=result_version,
                verification_status=VerificationStatus.FATAL_ERROR,
                issues_found=issues_summary,
                actions_taken="æ£€æµ‹åˆ°è‡´å‘½é”™è¯¯ï¼Œå»ºè®®Coordinatorç»ˆæ­¢æµç¨‹"
            )
            
            # âœ… è¿”å›è‡´å‘½é”™è¯¯æŠ¥å‘Š
            # Coordinatorä¼šæ ¹æ®FATAL_ERRORçŠ¶æ€å†³å®šæ˜¯å¦ç»ˆæ­¢
            return {
                **iteration_update,
                "verification_output": verification_output,
                "error_message": f"è‡´å‘½é”™è¯¯ï¼š{verification_output.rationale}",
                "needs_retry": False,
                # ä¸è®¾ç½®current_phaseï¼Œè®©Coordinatorå†³ç­–
                "messages": [AIMessage(content=f"âŒ è‡´å‘½é”™è¯¯ï¼š{verification_output.rationale}")]
            }
    
    except Exception as e:
        print(f"âŒ [Verification Agent] é”™è¯¯: {e}")
        return {
            "error_message": f"éªŒè¯å¤±è´¥: {str(e)}",
            "needs_retry": True
        }


def _generate_final_report(state: AgentState, config: Optional[Configuration] = None) -> str:
    """
    ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ˆç”±Coordinatorè°ƒç”¨ï¼‰
    
    èŒè´£ï¼š
    1. æ•´åˆæ‰€æœ‰æ™ºèƒ½ä½“çš„è¾“å‡º
    2. ç”Ÿæˆç»“æ„åŒ–çš„è§£é¢˜æŠ¥å‘Š
    3. ä½¿ç”¨LLMç”Ÿæˆä¸“ä¸šã€æ¸…æ™°çš„æŠ¥å‘Š
    """
    
    try:
        comprehension = state.get("comprehension_output")
        planning = state.get("planning_output")
        execution = state.get("execution_output")
        verification = state.get("verification_output")
        
        if not execution:
            return "âŒ é”™è¯¯ï¼šç¼ºå°‘æ‰§è¡Œç»“æœï¼Œæ— æ³•ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"
        
        # ä½¿ç”¨LLMç”Ÿæˆä¸“ä¸šçš„æœ€ç»ˆæŠ¥å‘Š
        llm = get_llm(config)
        
        report_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°å­¦è§£é¢˜æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½æ¸…æ™°ã€ä¸“ä¸šçš„è§£é¢˜æŠ¥å‘Šã€‚

ã€åŸå§‹é—®é¢˜ã€‘
{state.get('user_input')}

ã€é¢˜ç›®åˆ†æã€‘
{comprehension.model_dump_json(indent=2) if comprehension else 'æ— '}

ã€è§£é¢˜è®¡åˆ’ã€‘
{planning.model_dump_json(indent=2) if planning else 'æ— '}

ã€è®¡ç®—è¿‡ç¨‹ã€‘
{execution.model_dump_json(indent=2) if execution else 'æ— '}

ã€éªŒè¯ç»“æœã€‘
{verification.model_dump_json(indent=2) if verification else 'æ— '}

---

è¯·ç”Ÿæˆç»“æ„åŒ–çš„è§£é¢˜æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

## ğŸ“‹ é—®é¢˜ç†è§£
[ç®€è¦è¯´æ˜é—®é¢˜çš„ç±»å‹ã€å·²çŸ¥æ¡ä»¶ã€æ±‚è§£ç›®æ ‡]

## ğŸ¯ è§£é¢˜æ€è·¯
[è¯´æ˜é‡‡ç”¨çš„ç­–ç•¥å’Œæ–¹æ³•]

## ğŸ“ è§£é¢˜æ­¥éª¤
[è¯¦ç»†çš„è®¡ç®—è¿‡ç¨‹ï¼Œä½¿ç”¨æ¸…æ™°çš„æ­¥éª¤ç¼–å·]

## âœ… æœ€ç»ˆç­”æ¡ˆ
[æ˜ç¡®çš„æœ€ç»ˆç­”æ¡ˆï¼Œä½¿ç”¨é€‚å½“çš„æ ¼å¼ï¼ˆLaTeX/æ–‡æœ¬ï¼‰]

## ğŸ” éªŒè¯è¯´æ˜
[è¯´æ˜ç­”æ¡ˆå·²é€šè¿‡éªŒè¯ï¼Œç½®ä¿¡åº¦ç­‰]

è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼Œç¡®ä¿æŠ¥å‘Šä¸“ä¸šã€æ¸…æ™°ã€æ˜“è¯»ã€‚
        """
        
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°å­¦æ•™å¸ˆï¼Œæ“…é•¿æ’°å†™æ¸…æ™°ã€ä¸“ä¸šçš„è§£é¢˜æŠ¥å‘Šã€‚"),
            HumanMessage(content=report_prompt)
        ]
        
        print(f"  â†’ è°ƒç”¨LLMç”Ÿæˆä¸“ä¸šæŠ¥å‘Š...")
        final_report = llm.invoke(messages)
        
        return final_report.content
        
    except Exception as e:
        print(f"  âš ï¸ LLMç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
        # å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
        return _format_final_answer_simple(state)


def _format_final_answer_simple(state: AgentState) -> str:
    """ç®€åŒ–ç‰ˆæœ¬çš„æœ€ç»ˆç­”æ¡ˆæ ¼å¼åŒ–ï¼ˆä½œä¸ºå›é€€ï¼‰"""
    execution = state.get("execution_output")
    if not execution:
        return "âŒ æ— æ³•ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼šç¼ºå°‘æ‰§è¡Œç»“æœ"
    
    report = f"""
# è§£é¢˜æŠ¥å‘Š

## æœ€ç»ˆç»“æœ
{execution.final_result if execution.final_result else "è®¡ç®—å®Œæˆ"}

## è®¡ç®—è½¨è¿¹
"""
    for i, trace in enumerate(execution.computational_trace, 1):
        report += f"{i}. {trace}\n"
    
    # æ·»åŠ å·¥å…·è°ƒç”¨ä¿¡æ¯
    if execution.tool_executions:
        report += f"\n## å·¥å…·è°ƒç”¨è®°å½•\n"
        for tool_exec in execution.tool_executions:
            report += f"- ä»»åŠ¡ {tool_exec.task_id}: {tool_exec.tool_type.value}\n"
            report += f"  è¾“å‡º: {tool_exec.tool_output[:100]}...\n"
    
    return report